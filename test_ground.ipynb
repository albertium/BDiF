{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Invalid argument, error stack:\nMPI_FILE_IREAD_AT(100): Invalid offset argument",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ed0ceac2ba76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# read all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIread_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mMPI/File.pyx\u001b[0m in \u001b[0;36mmpi4py.MPI.File.Iread_at (src/mpi4py.MPI.c:136757)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Invalid argument, error stack:\nMPI_FILE_IREAD_AT(100): Invalid offset argument"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "import json\n",
    "\n",
    "# read parameters\n",
    "params =\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "mode = MPI.MODE_RDONLY\n",
    "fh = MPI.File.Open(comm, \"data-big.txt\", mode)\n",
    "\n",
    "# set read size parameter\n",
    "file_size = fh.Get_size()\n",
    "num_process = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "chunk_size = int(file_size / num_process)\n",
    "start = rank * chunk_size + 1\n",
    "\n",
    "# read all\n",
    "buf = bytearray(chunk_size)\n",
    "fh.Iread_at(start, buf)\n",
    "\n",
    "raw = buf.decode()\n",
    "\n",
    "print(\"Process\", rank, \"finish reading. Total size is\", len(raw), \"bytes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 finish Answer:  {'chunk_size': 100000}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "fh = MPI.File.Open(comm, \"config\", MPI.MODE_RDONLY)\n",
    "file_size = fh.Get_size()\n",
    "buf = bytearray(file_size)\n",
    "fh.Iread_at(0, buf)\n",
    "params = json.loads(buf.decode())\n",
    "\n",
    "# with open(\"config\", \"r\") as f:\n",
    "#     params = json.load(f)\n",
    "\n",
    "print(\"Process\", rank, \"finish\", \"Answer: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-874eacf3ec8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-874eacf3ec8d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "ts = [(x[0], float(x[1]), int(x[2])) for row in raw.split(\"\\n\") for x in [row.split(\",\")] if len(x) == 3]\n",
    "print(len(ts))\n",
    "print(ts[:5])\n",
    "print(ts[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20140804:10:00:00.574914,1173.56,471577\\n20140804:10:00:00.898688,1251.60,445361\\n20140804:10:00:00.94'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871\n1085\n99882\n0.49394\n"
     ]
    }
   ],
   "source": [
    "# find out the longest misplacement\n",
    "\n",
    "tmp = [x[0] for x in ts]\n",
    "rank = np.argsort(tmp)\n",
    "rev = np.maximum(rank - np.arange(len(tmp)), 0)\n",
    "cdf = np.sort(rev)\n",
    "\n",
    "print(cdf[99000]) # 99% quantile is 871\n",
    "print(cdf[99900]) # 99.9% quantile is 1085\n",
    "print(cdf[-1]) # 100% quantile is 99882\n",
    "print(np.sum(cdf>0)/len(cdf)) # 50% of records are misplaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicates - record, time, (price, vol)\n",
    "# a paper about filtering tick data\n",
    "# erratic price on thin volume\n",
    "# t2 from (t1, t2, t3) is out of wreck. use brownian bridge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "from operator import itemgetter\n",
    "\n",
    "def log(fh, rank, code, msg):\n",
    "    # code: 0 - Info, 1 - Warning, 2 - Error\n",
    "    codex = {0: \"INFO\", 1: \"WARNING\", 2: \"ERROR\"}\n",
    "    msg = \"[\" + str(rank) + \"][\" + codex[code] + \"]\" + \" (\" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") \\\n",
    "          + \"): \" + msg\n",
    "    fh.Write_shared(bytearray(msg.encode()))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # start MPI and get basic info\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    num_nodes = comm.Get_size()\n",
    "\n",
    "    # reset log file\n",
    "    if rank == 0:\n",
    "        try:\n",
    "            os.remove(\"log\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    flog = MPI.File.Open(comm, \"log\", MPI.MODE_WRONLY | MPI.MODE_CREATE)\n",
    "\n",
    "    # read parameters\n",
    "    try:\n",
    "        with open(\"config\", \"r\") as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        chunk_size = params[\"chunk_size\"]\n",
    "        chunk_buf = params[\"chunk_buf\"]\n",
    "        overlap_size = params[\"overlap_size\"]\n",
    "\n",
    "        log(flog, rank, 0, \"Loaded in parameters\")\n",
    "\n",
    "    except:\n",
    "        log(flog, rank, 2, \"Fail to load in parameters. Set to defaults\")\n",
    "\n",
    "        chunk_size = 10000\n",
    "        chunk_buf = 50\n",
    "        overlap_size = 1000\n",
    "\n",
    "\n",
    "\n",
    "    # read file in chunks\n",
    "    fh = MPI.File.Open(comm, \"data-small.txt\", MPI.MODE_RDONLY)\n",
    "    fsig = MPI.File.Open(comm, \"signal.txt\", MPI.MODE_WRONLY | MPI.MODE_CREATE)\n",
    "    fnoi = MPI.File.Open(comm, \"noise.txt\", MPI.MODE_WRONLY | MPI.MODE_CREATE)\n",
    "\n",
    "    file_size = fh.Get_size()\n",
    "    block_size = file_size / num_nodes\n",
    "    block_offset = rank * block_size\n",
    "\n",
    "    num_chunks = int(block_size // chunk_size)\n",
    "    overlap = []\n",
    "    for iter in range(1):\n",
    "        buf = bytearray(chunk_size + chunk_buf)\n",
    "        fh.Read_at(block_offset + iter * chunk_size, buf)\n",
    "\n",
    "        # discard everything before the first \"\\n\"\n",
    "        rows = buf[:chunk_size].decode().split(\"\\n\")[1:]\n",
    "\n",
    "        # get remaining part from the remainder\n",
    "        extra = buf[chunk_size:].decode().split(\"\\n\")[0]\n",
    "        # if last byte is \"\\n\", take one more record from the remainder\n",
    "        if buf[chunk_size - 1] == 10:\n",
    "            rows.append(extra)\n",
    "        else:\n",
    "            # append the remaining part of last row from the remainder\n",
    "            rows[-1] += extra\n",
    "\n",
    "        parsed = overlap + [(x[0], float(x[1]), int(x[2])) for row in rows for x in [row.split(\",\")]]\n",
    "        # sort by time\n",
    "        sorted_ix = np.argsort([x[0] for x in parsed])\n",
    "\n",
    "        signal = []\n",
    "        noise = []\n",
    "        for i, j in zip(sorted_ix[:-overlap_size], sorted_ix[1:-(overlap_size-1)]):\n",
    "            # filter by duplicates, price anomaly and negative volume\n",
    "            if parsed[i] == parsed[j] or parsed[i][1] <= 0 or parsed[i][1] > 50000 or parsed[i][2] <= 0:\n",
    "                noise.append(i)\n",
    "            else:\n",
    "                signal.append(i)\n",
    "\n",
    "        overlap = [parsed[ix] for ix in sorted_ix[-overlap_size:]]\n",
    "        \n",
    "        # output result\n",
    "        # fsig.Write_shared(bytearray(\"\\n\".join([parsed[ix] for ix in signal]).encode()))\n",
    "        # fnoi.Write_shared(bytearray(\"\\n\".join([parsed[ix] for ix in noise]).encode()))\n",
    "\n",
    "    # close files\n",
    "    flog.Close()\n",
    "    fh.Close()\n",
    "    fsig.Close()\n",
    "    fnoi.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/noise.txt\", \"r\") as f:\n",
    "    raw = f.read()\n",
    "\n",
    "to_compare = [row for row in raw.split(\"\\n\") if row]\n",
    "\n",
    "with open(\"output/noise_benchmark.txt\", \"r\") as f:\n",
    "    raw = f.read()\n",
    "\n",
    "bench = raw.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "A = [row for row in to_compare if row not in bench]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n"
     ]
    }
   ],
   "source": [
    "B = [row for row in bench if row not in to_compare]\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0799,1200.10,390294\\n20140804:1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/data-big.txt\", \"r\") as f:\n",
    "    f.seek(40000000)\n",
    "    raw = f.read(500050)\n",
    "\n",
    "raw[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}